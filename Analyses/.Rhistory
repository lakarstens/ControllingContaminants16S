cp_con <- cp_otus[,!colnames(cp_otus) %in% mock_taxa]
unk_con <- unk_otus[,!colnames(unk_otus) %in% mock_taxa]
# Sum the total amounts of contaminants across contaminant ASVs
con_otus <- rec_con +  blank_con + cp_con + unk_con
# Sum the total amount of contaminants per Samples sample
con_orig <- rowSums(con_otus)
#
all_otus <- rec_otus + blank_otus + cp_otus + unk_otus
# Chunk 6
all_otus <- rec_otus + blank_otus + cp_otus + unk_otus
results_st_sc1_case1 <- summarize_st(rec_otus,all_otus,mock_taxa, 'scenario 1 case 1')
summary_table(results_st_sc1_case1, 'scenario 1 case 1')
plot_st_classes(mock_taxa,rec_otus,all_otus,'Scenario 1, Case 1' )
# load results from running SourceTracker with contaminant profiles and black controls (Case 2 well-defined experimental community, blank only as contaminant profile)
rec_otus <- load_sourcetracker("./Sourcetracker_mock_b_30000/full_results/mock_b_MockCommunityProfile_contributions.txt", asv_key)
# load results from running SourceTracker with contaminant profiles and black controls (Case 2 well-defined experimental community, blank only as contaminant profile)
rec_otus <- load_sourcetracker("./Sourcetracker_mock_b_30000/full_results/mock_b_MockCommunityProfile_contributions.txt", asv_key)
blank_otus <- load_sourcetracker("./Sourcetracker_mock_b_30000/full_results/mock_b_Blank_contributions.txt", asv_key)
unk_otus <- load_sourcetracker("./Sourcetracker_mock_b_30000/full_results/mock_b_Unknown_contributions.txt", asv_key)
# determine total amounts of conatmiants across the dataset
rec_con <- rec_otus[,!colnames(rec_otus) %in% mock_taxa]
blank_con<- blank_otus[,!colnames(blank_otus) %in% mock_taxa]
unk_con <- unk_otus[,!colnames(unk_otus) %in% mock_taxa]
con_otus <- rec_con +  blank_con + unk_con
con_orig <- rowSums(con_otus)
# identify mock community ASVs correctly and incorrectly classified
mock_c <- rowSums(rec_otus[,colnames(rec_otus) %in% mock_taxa])
mock_i <- rowSums(rec_otus[,!colnames(rec_otus) %in% mock_taxa])
# identify contaminants correctly identified as contaminants
blank_c <- rowSums(blank_otus[,!colnames(blank_otus) %in% mock_taxa])
unk_c <- rowSums(unk_otus[,!colnames(unk_otus) %in% mock_taxa])
# identify mock microbial community ASVs incorrectly identified as contaminants
blank_i <- rowSums(blank_otus[,colnames(blank_otus) %in% mock_taxa])
unk_i <- rowSums(unk_otus[,colnames(unk_otus) %in% mock_taxa])
st_profile <- rbind(mock_i,blank_i,unk_i,mock_c, blank_c, unk_c)
long_st_profile <- melt(data = st_profile,
id.vars = rownames(),
variable.name = colnames(),
value.name = "Abundance"
)
customPalette <- c('#969696','#bdbdbd','#f0f0f0', '#1B9E77', '#E7298A', '#7570B3')
# Figure 5C
ggplot(long_st_profile, aes(x = Var2, y = Abundance)) + geom_col(aes(fill = Var1), width = 0.7, position = position_fill())  + scale_fill_manual(values=customPalette) + theme(text = element_text(size=12)) + labs(x = "Samples", y = 'Proportion of Reads')
all_otus <- rec_otus + blank_otus + unk_otus
results_st_sc1_case2 <- summarize_st(rec_otus,all_otus,mock_taxa,'scenario 1 case 2')
summary_table(results_st_sc1_case2, 'scenario 1 case 2')
recovered_otus <- rec_otus
# for simplicity, all other classifications are 'contaminants'
removed_otus <- all_otus - recovered_otus
con_orig <- rowSums(all_otus[,!colnames(all_otus) %in% mock_taxa])
mock_orig <- rowSums(all_otus[,colnames(all_otus) %in% mock_taxa])
#  % of mock community ASVs correctly classified as mock community ASVs
true_neg <- rowSums(recovered_otus[,colnames(recovered_otus) %in% mock_taxa])
# % of mock community incorrectly classified as non-mock community ASVs
false_neg <- rowSums(recovered_otus[,!colnames(recovered_otus) %in% mock_taxa])
#  identify non-mock community ASVs correctly classified as not belonging to mock   community
true_pos <- rowSums(removed_otus[,!colnames(removed_otus) %in% mock_taxa])
#  identify mock community ASVs incorrectly classified as not belonging to mock   community
false_pos <- rowSums(removed_otus[,colnames(removed_otus) %in% mock_taxa])
sensitivity <- true_pos/(true_pos + false_neg)
specificty <- true_neg/(true_neg + false_pos)
accuracy <- (true_pos + true_neg) / (false_pos + true_pos + false_neg + true_neg)
prevalence <- (true_pos + false_neg) / (false_pos + true_pos + false_neg + true_neg)
# Summarize results
## proportion of contaminants removed (of all total contaminant ASVs)
contaminants_removed = (rowSums(removed_otus[,!colnames(removed_otus) %in% mock_taxa])/ con_orig) * 100
## proportion of mock removed (of all total mock ASVs)
mock_ASVs_removed = (rowSums(removed_otus[,colnames(removed_otus) %in% mock_taxa])/ mock_orig) * 100
false_neg
true_neg
true_pos
false_pos
false_pos*100
true_pos*100
true_neg*100
false_neg*100
mock_orig
mock_orig*100
false_pos*100
true_pos*100
# Chunk 1: set workspace
# load libraries
library(phyloseq)
library(ggplot2)
library(tidyverse)
library(RColorBrewer)
library(reshape2)
library(knitr)
library(dplyr)
# save session info (packages and versions loaded)
session <- sessionInfo()
# Chunk 1: set workspace
# load libraries
library(phyloseq)
library(ggplot2)
library(tidyverse)
library(RColorBrewer)
library(reshape2)
library(knitr)
library(dplyr)
# save session info (packages and versions loaded)
session <- sessionInfo()
# Chunk 2: defineFunctions
# Create function to plot bar plots with contaminants in grey scale and expected mock community sequences in color
expCompBarPlot <- function(physeq, exp_taxa, title){
## physeq - phyloseq object that will be plotted
## exp_taxa - taxa that are expected to be in the mock community
## title - title for plot
#set up data_table
data_table <- as.data.frame(t(physeq@otu_table))
data_table$reference = FALSE
data_table$reference[rownames(data_table) %in% exp_taxa] = TRUE
sample_names <- sample_names(physeq)
data_table$id <- paste0('ASV_', 1:nrow(data_table))
dilution_labels <- sample_data(physeq)$Dilutions
set.seed(444)
# define the colors to use for reference and non-reference OTUs/ASVs
ref_colors <- brewer.pal(sum(data_table$reference), "Paired")
other_colors <- sample(grey.colors(5, start = 0.5, end = 0.9), sum(!data_table$reference), replace = TRUE)
# add a color variable to the data table
data_table$color <- rep(NA, nrow(data_table))
data_table$color[data_table$reference] <- ref_colors
data_table$color[!data_table$reference] <- other_colors
# reshape the data table into a ggplot-friendly format, by gathering samples into a single column called "count"
color_gg <- data_table %>% select(id, sample_names, color) %>% gather("sample", "count", sample_names)
legend_color <- c(bright = ref_colors[2], dull = other_colors[2])
data_gg <- data_table %>% gather("sample", "count", sample_names)
data_gg <- inner_join(data_gg,color_gg)
# create the composition bar plot
comp_bar <- ggplot(data_gg, aes(x = sample, y = count)) +
geom_col(aes(fill = color, group = reference, alpha = ifelse(reference, "bright", "dull")), width = 0.7, position = position_fill()) +
scale_fill_identity(guide = FALSE) +
scale_alpha_manual(name = "Sequence type",
labels = c("expected sequences", "other"),
values = c(bright = 1, dull = 1),
guide = guide_legend(override.aes = list(fill = c(ref_colors[4], "#AEAEAE")),
keywidth = NULL, keyheight = NULL)) +
labs(title = title, x = "sample", y = "Relative Abundance") +
theme(legend.position = "right", legend.title = element_text(size = 12),
axis.text = element_text(size = 12),
axis.title = element_text(size = 16),
plot.title = element_text(size = 16))
comp_bar
}
# Chunk 3: loadData
## Load the dataset
load("mockDilutions.RData")
# Chunk 4
# Create profile of only expected sequences from the undiluted mock communtiy sample
# subset the undiluted mock microbial sample (sample name 'D0')
mock_ps_pure <- subset_samples(mock_ps,sample_names(mock_ps)== 'D0')
# remove ASVs that are not present in the undiluted sample
mock_ps_pure <- prune_taxa(taxa_sums(mock_ps_pure)>0,mock_ps_pure)
# change the SampleType and sample_names of the pure mock microbial community sample
sample_data(mock_ps_pure)$SampleType <-'MockCommunityProfile'
sample_names(mock_ps_pure) <-paste('mc',sample_names(mock_ps_pure),sep = '_')
# display a summary of the new phyloseq object
mock_ps_pure
# make a list of the top 9 abundant ASV taxa names (this is plausible for filtering since the 9 sequences we want to remove are present in low abundance)
mock_taxa = names(sort(taxa_sums(mock_ps_pure), decreasing = TRUE)[1:9])
# subset the taxa in mock_ps_pure so only the expected sequences are present
mock_ps_pure<-prune_taxa(mock_taxa,mock_ps_pure)
# Chunk 1: set workspace
# load libraries
library(phyloseq)
library(ggplot2)
library(tidyverse)
library(RColorBrewer)
library(reshape2)
library(knitr)
library(dplyr)
# save session info (packages and versions loaded)
session <- sessionInfo()
# Chunk 2: defineFunctions
# Create function to plot bar plots with contaminants in grey scale and expected mock community sequences in color
expCompBarPlot <- function(physeq, exp_taxa, title){
## physeq - phyloseq object that will be plotted
## exp_taxa - taxa that are expected to be in the mock community
## title - title for plot
#set up data_table
data_table <- as.data.frame(t(physeq@otu_table))
data_table$reference = FALSE
data_table$reference[rownames(data_table) %in% exp_taxa] = TRUE
sample_names <- sample_names(physeq)
data_table$id <- paste0('ASV_', 1:nrow(data_table))
dilution_labels <- sample_data(physeq)$Dilutions
set.seed(444)
# define the colors to use for reference and non-reference OTUs/ASVs
ref_colors <- brewer.pal(sum(data_table$reference), "Paired")
other_colors <- sample(grey.colors(5, start = 0.5, end = 0.9), sum(!data_table$reference), replace = TRUE)
# add a color variable to the data table
data_table$color <- rep(NA, nrow(data_table))
data_table$color[data_table$reference] <- ref_colors
data_table$color[!data_table$reference] <- other_colors
# reshape the data table into a ggplot-friendly format, by gathering samples into a single column called "count"
color_gg <- data_table %>% select(id, sample_names, color) %>% gather("sample", "count", sample_names)
legend_color <- c(bright = ref_colors[2], dull = other_colors[2])
data_gg <- data_table %>% gather("sample", "count", sample_names)
data_gg <- inner_join(data_gg,color_gg)
# create the composition bar plot
comp_bar <- ggplot(data_gg, aes(x = sample, y = count)) +
geom_col(aes(fill = color, group = reference, alpha = ifelse(reference, "bright", "dull")), width = 0.7, position = position_fill()) +
scale_fill_identity(guide = FALSE) +
scale_alpha_manual(name = "Sequence type",
labels = c("expected sequences", "other"),
values = c(bright = 1, dull = 1),
guide = guide_legend(override.aes = list(fill = c(ref_colors[4], "#AEAEAE")),
keywidth = NULL, keyheight = NULL)) +
labs(title = title, x = "sample", y = "Relative Abundance") +
theme(legend.position = "right", legend.title = element_text(size = 12),
axis.text = element_text(size = 12),
axis.title = element_text(size = 16),
plot.title = element_text(size = 16))
comp_bar
}
# Chunk 3: loadData
## Load the dataset
load("mockDilutions.RData")
# Chunk 4
# Create profile of only expected sequences from the undiluted mock communtiy sample
# subset the undiluted mock microbial sample (sample name 'D0')
mock_ps_pure <- subset_samples(mock_ps,sample_names(mock_ps)== 'D0')
# remove ASVs that are not present in the undiluted sample
mock_ps_pure <- prune_taxa(taxa_sums(mock_ps_pure)>0,mock_ps_pure)
# change the SampleType and sample_names of the pure mock microbial community sample
sample_data(mock_ps_pure)$SampleType <-'MockCommunityProfile'
sample_names(mock_ps_pure) <-paste('mc',sample_names(mock_ps_pure),sep = '_')
# display a summary of the new phyloseq object
mock_ps_pure
# make a list of the top 9 abundant ASV taxa names (this is plausible for filtering since the 9 sequences we want to remove are present in low abundance)
mock_taxa = names(sort(taxa_sums(mock_ps_pure), decreasing = TRUE)[1:9])
# subset the taxa in mock_ps_pure so only the expected sequences are present
mock_ps_pure<-prune_taxa(mock_taxa,mock_ps_pure)
# display a summary of the mock community dilution series phyloseq object
mock_ps
temp<-as.matrix(ps@tax_table)
temp<-as.matrix(mock_ps_pure@tax_table)
View(mock_ps_pure)
temp<-as.matrix(mock_ps_pure@tax_table)
temp <- as.data.frame(temp)
View(temp)
# create a phyloseq object that is normalized to 100 (relative abundance)
ps_norm <- transform_sample_counts(ps,function(x) 100* x/sum(x))
mock_ps_norm <- transform_sample_counts(mock_ps,function(x) 100* x/sum(x))
# Identify the proportion of each sample that is the expected mock community ASVs
ps_norm_exp <- prune_taxa(mock_taxa,ps_norm)
# Create a table with the dilution, number of reads per sample, and proportion of contaminants per sample
dilutionSummary <- data.frame(DilutionSeries = sample_names(ps),NumberOfReads = sample_sums(ps), PercentContaminants = 100-sample_sums(ps_norm_exp))
# Create a variable to indicate the sample order of the plots
dilutions<-c('D0','D1','D2','D3','D4','D5','D6','D7','D8', 'Blank')
# Create a table with the dilution, number of reads per sample, and proportion of contaminants per sample
dilutionSummary <- data.frame(DilutionSeries = sample_names(ps),NumberOfReads = sample_sums(mock_ps), PercentContaminants = 100-sample_sums(ps_norm_exp))
# Create plots to summarize these data
## Plot Figure 1A - number of reads per sample across dilution series
dilutionSummary %>% subset(DilutionSeries %in% dilutions[1:9] ) %>%
ggplot(., aes(x = DilutionSeries, y = NumberOfReads)) + geom_bar(stat="identity", fill="steelblue") +
theme_minimal() + scale_x_discrete(limits = dilutions) +
labs(x = "Dilution Series", y = "Number of Reads") +
theme(axis.text = element_text(size = 14),
axis.title = element_text(size = 16),
plot.title = element_text(size = 16))
## Plot Figure 1B - Percent of contaminants across dilution series
dilutionSummary %>% subset(DilutionSeries %in% dilutions[1:9] ) %>%
ggplot(., aes(x = DilutionSeries, y = PercentContaminants)) + geom_point(size = 3) + scale_x_discrete(limits = dilutions) +
labs(x = "Dilution Series", y = "Number of Reads") +
theme(axis.text = element_text(size = 14),
axis.title = element_text(size = 16),
plot.title = element_text(size = 16))
## Plot Figure 1C - Stacked bar plot of Mock microbial dilution series
expCompBarPlot(ps_norm, mock_taxa, 'Initial Mock Microbial Community Dilution')  + scale_x_discrete(limits = dilutions)
# create a list of all ASV taxa names
contaminant_taxa<-taxa_names(mock_ps)
# remove the expected mock community ASV taxa names
contaminant_taxa <- contaminant_taxa[!(contaminant_taxa %in% mock_taxa)]
# create a phyloseq object that only contains the contaminant sequences
contaminants_ps<-prune_taxa(contaminant_taxa,mock_ps)
contaminants_ps<- prune_taxa(taxa_sums(contaminants_ps)>0,contaminants_ps)
# change the sample names to indicate that these samples only contain contmaminant ASVs
sample_names(contaminants_ps)<-paste('con',sample_names(contaminants_ps),sep = '_')
sample_data(contaminants_ps)$SampleType<-'ContaminantProfile'
# Number of ASVs in common between contaminants in mock community and the blank control
print(paste('Total number of contaminant ASVs', length(taxa_names(contaminants_ps))))
print(paste('Number of contaminant ASVs also present in blank', length(intersect(taxa_names(contaminants_ps),taxa_names(blank_ps)))))
# create a list of contaminants taxa that are not present in the blank control
contaminant_taxa_no_blank<-taxa_names(contaminants_ps)
contaminant_taxa_no_blank <- contaminant_taxa_no_blank[!(contaminant_taxa_no_blank %in% taxa_names(blank_ps))]
# Create  a binary list of contaminant ASVs indicating if the ASV is present in the blank control (1) or not (0)
contaminants_in_blank <- data.frame(matrix(1, ncol = length(taxa_names(contaminants_ps)), nrow = 1))
colnames(contaminants_in_blank) <- taxa_names(contaminants_ps)
contaminants_in_blank[,contaminant_taxa_no_blank] <- 0
contaminants_in_blank <- t(contaminants_in_blank)
dim(contaminants_in_blank)
dim(contaminant_taxa_no_blank
)
# Identify the contribution per sample of contaminants that are not present in blanks
# generate a phyloseq object with contaminants only normalized to 100
contaminant_ps_norm <- transform_sample_counts(contaminants_ps,function(x) 100* x/sum(x))
contaminant_no_blanks<-prune_taxa(contaminant_taxa_no_blank,contaminant_ps_norm)
# Plot the proportion of contaminant ASVs per sample that were not present in the blank control
plot_bar(contaminant_no_blanks,fill='Genus',, title = ' Proportion of Contaminant ASVs Not in the Blank Control Sample') + theme(legend.position='none') + ylim(c(0,100))
# sum the amount of contaminant signal not arising from ASVs in blank control
100 - sample_sums(contaminant_no_blanks)
summary(100 - sample_sums(contaminant_no_blanks))
# Count number of contaminants present in only one sample
contaminant_bin<-as.data.frame(contaminants_ps@otu_table)
contaminant_bin[contaminant_bin>0]<-1
contaminant_bin = t(contaminant_bin)
contaminant_nsamples <- rowSums(contaminant_bin)
table(contaminant_nsamples)
# identify the maximum proportion of reads for each contaminant ASV
contaminant_max <- apply(as.data.frame(mock_ps_norm@otu_table), 2, max)
contaminant_max <- subset(contaminant_max, names(contaminant_max) %in% contaminant_taxa)
contaminant_max
# summarize in table (Supplemental Table 2)
contaminantSummary <- cbind( ASV = names(contaminant_max),as.data.frame(contaminants_ps@tax_table), Maximum = contaminant_max, Minimum = contaminant_min, NumberOfSamples = contaminant_nsamples, InBlank =  contaminants_in_blank)
# identify the minimum proportion of reads for each contaminant ASV
contaminant_min <- apply(as.data.frame(mock_ps_norm@otu_table), 2, min)
contaminant_min <- subset(contaminant_min, names(contaminant_min) %in% contaminant_taxa)
# summarize in table (Supplemental Table 2)
contaminantSummary <- cbind( ASV = names(contaminant_max),as.data.frame(contaminants_ps@tax_table), Maximum = contaminant_max, Minimum = contaminant_min, NumberOfSamples = contaminant_nsamples, InBlank =  contaminants_in_blank)
contaminantSummary
table(contaminantSummary)
table(contaminantSummary$InBlank)
sample_sums(ps)
# Chunk 1: set workspace
# load libraries
library(phyloseq)
library(ggplot2)
library(tidyverse)
library(RColorBrewer)
library(reshape2)
library(knitr)
library(dplyr)
# save session info (packages and versions loaded)
session <- sessionInfo()
# Chunk 2: defineFunctions
# Create function to plot bar plots with contaminants in grey scale and expected mock community sequences in color
expCompBarPlot <- function(physeq, exp_taxa, title){
## physeq - phyloseq object that will be plotted
## exp_taxa - taxa that are expected to be in the mock community
## title - title for plot
#set up data_table
data_table <- as.data.frame(t(physeq@otu_table))
data_table$reference = FALSE
data_table$reference[rownames(data_table) %in% exp_taxa] = TRUE
sample_names <- sample_names(physeq)
data_table$id <- paste0('ASV_', 1:nrow(data_table))
dilution_labels <- sample_data(physeq)$Dilutions
set.seed(444)
# define the colors to use for reference and non-reference OTUs/ASVs
ref_colors <- brewer.pal(sum(data_table$reference), "Paired")
other_colors <- sample(grey.colors(5, start = 0.5, end = 0.9), sum(!data_table$reference), replace = TRUE)
# add a color variable to the data table
data_table$color <- rep(NA, nrow(data_table))
data_table$color[data_table$reference] <- ref_colors
data_table$color[!data_table$reference] <- other_colors
# reshape the data table into a ggplot-friendly format, by gathering samples into a single column called "count"
color_gg <- data_table %>% select(id, sample_names, color) %>% gather("sample", "count", sample_names)
legend_color <- c(bright = ref_colors[2], dull = other_colors[2])
data_gg <- data_table %>% gather("sample", "count", sample_names)
data_gg <- inner_join(data_gg,color_gg)
# create the composition bar plot
comp_bar <- ggplot(data_gg, aes(x = sample, y = count)) +
geom_col(aes(fill = color, group = reference, alpha = ifelse(reference, "bright", "dull")), width = 0.7, position = position_fill()) +
scale_fill_identity(guide = FALSE) +
scale_alpha_manual(name = "Sequence type",
labels = c("expected sequences", "other"),
values = c(bright = 1, dull = 1),
guide = guide_legend(override.aes = list(fill = c(ref_colors[4], "#AEAEAE")),
keywidth = NULL, keyheight = NULL)) +
labs(title = title, x = "sample", y = "Relative Abundance") +
theme(legend.position = "right", legend.title = element_text(size = 12),
axis.text = element_text(size = 12),
axis.title = element_text(size = 16),
plot.title = element_text(size = 16))
comp_bar
}
# Chunk 3: loadData
## Load the dataset
load("mockDilutions.RData")
sample_sums(ps)
sum(sample_sums(ps))
ps
max(sample_sums(mock_ps))
# number of ASVs
ps_D0 <- subset_samples(sample_names(ps_mock) == 'D0')
# number of ASVs
ps_D0 <- subset_samples(sample_names(mock_ps) == 'D0')
# number of ASVs
ps_D0 <- subset_samples(sample_names(mock_ps) == 'D0')
## Table 1
# Number of sequences per sample
sample_sums(mock_ps)
sample_names(mock_ps)
# number of ASVs
ps_D0 <- subset_samples(sample_names(mock_ps) == 'D0', mock_ps)
# number of ASVs
ps_D0 <- subset_samples(mock_ps,sample_names(mock_ps) == 'D0')
ps_D0 <- prune_taxa(taxa_sums(ps_D0)>0,ps_D0)
ps_D0
length(ps_D0@tax_table)
dim(ps_D0@tax_table)
#18 ASVs
tax_glom(ps_D0, 'Genus')
# 18 ASVs
print(tax_glom(ps_D0, 'Genus'))
ps_temp <- subset_samples(mock_ps,sample_names(mock_ps) == sample)
# number of ASVs and genera per sample - there is probably a better way
summarize_sample <- function(ps, sample){
ps_temp <- subset_samples(mock_ps,sample_names(mock_ps) == sample)
ps_temp <- prune_taxa(taxa_sums(ps_temp)>0,ps_temp)
print(paste0(sample,' Number ASVs: ',dim(ps_temp@tax_table)))
ps_temp <- tax_glom(ps_temp, 'Genus')
print(paste0(sample, ' Number Genera: ',dim(ps_temp@tax_table)))
}
summarize_sample(mock_ps, 'D0')
# number of ASVs and genera per sample - there is probably a better way
summarize_sample <- function(physeq, sample){
ps_temp <- subset_samples(physeq,sample_names(physeq) == sample)
ps_temp <- prune_taxa(taxa_sums(ps_temp)>0,ps_temp)
print(paste0(sample,' Number ASVs: ',dim(ps_temp@tax_table)))
ps_temp <- tax_glom(ps_temp, 'Genus')
print(paste0(sample, ' Number Genera: ',dim(ps_temp@tax_table)))
}
summarize_sample(mock_ps, 'D0')
physeq = mock_ps
sample = 'D0'
ps_temp <- subset_samples(physeq,sample_names(physeq) == sample)
sample
sample_names(physeq)
physeq
ps_temp <- subset_samples(physeq,sample_names(physeq) == sample_id)
# number of ASVs and genera per sample - there is probably a better way
summarize_sample <- function(physeq, sample_id){
ps_temp <- subset_samples(physeq,sample_names(physeq) == sample_id)
ps_temp <- prune_taxa(taxa_sums(ps_temp)>0,ps_temp)
print(paste0(sample,' Number ASVs: ',dim(ps_temp@tax_table)))
ps_temp <- tax_glom(ps_temp, 'Genus')
print(paste0(sample, ' Number Genera: ',dim(ps_temp@tax_table)))
}
ps_temp <- subset_samples(physeq,sample_names(physeq) == sample_id)
summarize_sample(mock_ps, 'D0')
# number of ASVs and genera per sample - there is probably a better way
summarize_sample <- function(physeq, sample_id){
ps_temp <- subset_samples(physeq,sample_names(physeq) == sample_id)
ps_temp <- prune_taxa(taxa_sums(ps_temp)>0,ps_temp)
print(paste0(sample,' Number ASVs: ',dim(ps_temp@tax_table)))
ps_temp <- tax_glom(ps_temp, 'Genus')
print(paste0(sample, ' Number Genera: ',dim(ps_temp@tax_table)))
}
summarize_sample(mock_ps, 'D0')
sample_is
sample_id
sample_id <- 'D0'
summarize_sample(mock_ps, 'D0')
summarize_sample(mock_ps, 'D1')
summarize_sample(mock_ps, sample_id = 'D1')
summarize_sample(mock_ps, sample_id = 'D5')
# number of ASVs and genera per sample - there is probably a better way
summarize_sample <- function(ps_obj, sample_id){
ps_temp <- subset_samples(ps_obj,sample_names(ps_obj) == sample_id)
ps_temp <- prune_taxa(taxa_sums(ps_temp)>0,ps_temp)
print(paste0(sample,' Number ASVs: ',dim(ps_temp@tax_table)))
ps_temp <- tax_glom(ps_temp, 'Genus')
print(paste0(sample, ' Number Genera: ',dim(ps_temp@tax_table)))
}
summarize_sample(mock_ps, sample_id = 'D5')
# number of ASVs and genera per sample - there is probably a better way
summarize_sample <- function(ps_obj, sample_id){
ps_temp <- subset_samples(ps_obj,sample_names(ps_obj) == sample_id)
ps_temp <- prune_taxa(taxa_sums(ps_temp)>0,ps_temp)
print(paste0(sample,' Number ASVs: ',dim(ps_temp@tax_table)))
ps_temp <- tax_glom(ps_temp, 'Genus')
print(paste0(sample, ' Number Genera: ',dim(ps_temp@tax_table)))
}
summarize_sample(mock_ps, sample_id = 'D5')
# number of ASVs and genera per sample - there is probably a better way
summarize_sample <- function(ps_obj, sample_id){
ps_temp <- subset_samples(ps_obj,sample_names(ps_obj) == sample_id)
ps_temp <- prune_taxa(taxa_sums(ps_temp)>0,ps_temp)
print(paste0(sample,' Number ASVs: ',dim(ps_temp@tax_table)))
ps_temp <- tax_glom(ps_temp, 'Genus')
print(paste0(sample, ' Number Genera: ',dim(ps_temp@tax_table)))
}
summarize_sample(ps_obj = mock_ps, sample_id = 'D1')
# number of ASVs and genera per sample - there is probably a better way
summarize_sample <- function(ps_obj, sample_id){
ps_temp <- subset_samples(ps_obj,sample_names(ps_obj) == sample_id)
ps_temp <- prune_taxa(taxa_sums(ps_temp)>0,ps_temp)
print(paste0(sample,' Number ASVs: ',dim(ps_temp@tax_table)))
ps_temp <- tax_glom(ps_temp, 'Genus')
print(paste0(sample, ' Number Genera: ',dim(ps_temp@tax_table)))
}
summarize_sample(mock_ps, sample_id = 'D5')
# number of ASVs and genera per sample - there is probably a better way
summarize_sample <- function(mock_ps, sample_id){
ps_temp <- subset_samples(ps_obj,sample_names(ps_obj) == sample_id)
ps_temp <- prune_taxa(taxa_sums(ps_temp)>0,ps_temp)
print(paste0(sample,' Number ASVs: ',dim(ps_temp@tax_table)))
ps_temp <- tax_glom(ps_temp, 'Genus')
print(paste0(sample, ' Number Genera: ',dim(ps_temp@tax_table)))
}
summarize_sample(mock_ps, sample_id = 'D5')
# number of ASVs and genera per sample - there is probably a better way
summarize_sample <- function(mock_ps, sample_id){
ps_temp <- subset_samples(mock_ps,sample_names(mock_ps) == sample_id)
ps_temp <- prune_taxa(taxa_sums(ps_temp)>0,ps_temp)
print(paste0(sample,' Number ASVs: ',dim(ps_temp@tax_table)))
ps_temp <- tax_glom(ps_temp, 'Genus')
print(paste0(sample, ' Number Genera: ',dim(ps_temp@tax_table)))
}
summarize_sample(mock_ps, sample_id = 'D5')
